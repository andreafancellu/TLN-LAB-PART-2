{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import framenet as fn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Id estratti dai cognomi per i seguenti frame: \n",
    "- 'Chemical_potency', 'Fullness', 'Causation', 'Disgraceful_situation', 'Obviousness'\n",
    "- 'Infrastructure', 'Product_line', 'Gusto', 'Military', 'Terrorism'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [2724, 244, 5, 1612, 1360, 1481, 2524, 2569, 1514, 1750]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metodi utili per fare pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(text):\n",
    "    result = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word in text:\n",
    "        result.append(lemmatizer.lemmatize(word))\n",
    "    return result\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    return re.sub(r'[^\\w\\s]', '', s)\n",
    "\n",
    "def remove_stop_words(row):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_sentence = [w for w in row if not w.lower() in stop_words]\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estrapolazione del contesto dal synset\n",
    "Obiettivo è creare una lista che contenga i termini rilevanti per creare un contesto del synset. I termini rilevanti sono all'interno di:\n",
    "- definizione del synset;\n",
    "- esempi del synset;\n",
    "- lemmi;\n",
    "- definizioni di iponimi e iperonimi.\n",
    "- esempi di iponimi e iperonimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synset_ctx(synset):\n",
    "    defs = remove_punctuation(synset.definition())\n",
    "    exs = remove_punctuation(' '.join(synset.examples()))\n",
    "    defs = remove_stop_words(lemmatize_words(defs.split()))\n",
    "    exs = remove_stop_words(lemmatize_words(exs.split()))\n",
    "\n",
    "    hypo = synset.hyponyms()\n",
    "    hyper = synset.hypernyms()\n",
    "    lemmas = synset.lemmas()\n",
    "    \n",
    "    lems = []\n",
    "    for l in lemmas:\n",
    "        lems = lems + l.name().split(\"_\")\n",
    "\n",
    "    for h in hypo:\n",
    "        defs = defs + remove_stop_words(lemmatize_words(remove_punctuation(h.definition()).split()))\n",
    "        exs = exs + remove_stop_words(lemmatize_words(remove_punctuation(' '.join(h.examples())).split()))\n",
    "    \n",
    "    for h in hyper:\n",
    "        defs = defs + remove_stop_words(lemmatize_words(remove_punctuation(h.definition()).split()))\n",
    "        exs = exs + remove_stop_words(lemmatize_words(remove_punctuation(' '.join(h.examples())).split()))\n",
    "\n",
    "    return defs + exs + lems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estrapolazione del contesto dal frame\n",
    "Obiettivo è creare una lista che contenga i termini rilevanti per creare un contesto del frame. I termini rilevanti sono presi sia dalla definizione del frame sia dalla definizione dei FEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_ctx(id):\n",
    "    ctx = []\n",
    "    frame = fn.frame_by_id(id)\n",
    "    ctx = ctx + frame.name.split(' ')\n",
    "    defs = remove_punctuation(frame.definition)\n",
    "    defs = remove_stop_words(defs.split(\" \"))\n",
    "    ctx = ctx + lemmatize_words(defs)\n",
    "    \n",
    "    for fe in frame.FE:\n",
    "        fe_defs = remove_punctuation(frame.FE[fe].definition)\n",
    "        fe_defs = remove_stop_words(fe_defs.split(\" \"))\n",
    "        ctx = ctx + lemmatize_words(fe_defs)\n",
    "    return ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approccio Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(frame_context, synset_context):\n",
    "    return len([word for word in frame_context if word in synset_context]) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metodo per valutazione sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation(result_dict, annotation_dict):\n",
    "    count_eval = 0\n",
    "    len_total = 0\n",
    "    for k in result_dict.keys():\n",
    "        len_total += len(result_dict[k].keys())\n",
    "        for el in result_dict[k].keys():\n",
    "            if result_dict[k][el] == annotation_dict[k][el]:\n",
    "                count_eval += 1\n",
    "\n",
    "    return count_eval / len_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La valutazione del sistema è del: 49.67%\n"
     ]
    }
   ],
   "source": [
    "annotation_dict = {\n",
    "    'Chemical_potency': {\n",
    "        'Chemical_potency':'chemical.n.01',\n",
    "        'Chemical_entity':'chemical.n.01',\n",
    "        'Degree':'degree.n.02',\n",
    "        'Time':'time.n.03',\n",
    "        'Circumstances':'circumstance.n.01',\n",
    "        'Place':'place.n.02',\n",
    "        'strong.a':'strong.a.01',\n",
    "        'potent.a':'potent.s.02',\n",
    "        'stiff.a':'potent.a.03'\n",
    "    },\n",
    "    'Fullness': {\n",
    "        'Fullness': 'fullness.n.03',\n",
    "        'Container' : 'container.n.01',\n",
    "        'Contents': 'content.n.01',\n",
    "        'Degree': 'degree.n.01',\n",
    "        'Time': 'time.n.03',\n",
    "        'Frequency': 'frequency.n.01',\n",
    "        'Duration': 'duration.n.01',\n",
    "        'full.a': 'full.a.01',\n",
    "        'empty.a': 'empty.a.01',\n",
    "        'emptiness.n': 'emptiness.n.01',\n",
    "        'fullness.n': 'fullness.n.03'\n",
    "    },\n",
    "    'Causation': {\n",
    "        'Causation': 'causing.n.01',\n",
    "        'Cause': 'cause.n.01',\n",
    "        'Affected': 'affected.a.01',\n",
    "        'Effect': 'consequence.n.01',\n",
    "        'Place': 'place.n.02',\n",
    "        'Time': 'time.n.03',\n",
    "        'Actor': 'actor.n.02',\n",
    "        'Circumstances': 'context.n.02',\n",
    "        'Manner': 'manner.n.01',\n",
    "        'Explanation': 'explanation.n.01',\n",
    "        'Means': 'means.n.01',\n",
    "        'Frequency': 'frequency.n.01',\n",
    "        'Concessive': 'concessive.a.01',\n",
    "        'cause.v':'cause.v.01',\n",
    "        'cause.n':'cause.n.01',\n",
    "        'make.v':'make.v.03',\n",
    "        'lead (to).v':'lead.v.03',\n",
    "        'reason.n':'cause.n.02',\n",
    "        'send.v':'send.v.01',\n",
    "        'bring about.v':'bring.v.03',\n",
    "        'precipitate.v':'precipitate.v.01',\n",
    "        'causative.a':'causative.a.1',\n",
    "        'render.v':'render.v.01',\n",
    "        'bring.v':'bring.v.02',\n",
    "        'bring on.v':'bring.v.02',\n",
    "        'induce.v':'induce.v.01',\n",
    "        'wreak.v':'bring.v.03',\n",
    "        'put.v':'put.v.02',\n",
    "        'since.c': None,\n",
    "        'because.c': None,\n",
    "        'because of.prep': None,\n",
    "        'raise.v':'raise.v.03',\n",
    "        'result (in).v':'result.v.01'\n",
    "    },\n",
    "    'Disgraceful_situation': {\n",
    "        'Disgraceful_situation': 'disgraceful.s.01',\n",
    "        'State_of_affairs': 'state.n.02',\n",
    "        'Protagonist': 'protagonist.n.02',\n",
    "        'Degree': 'degree.n.01',\n",
    "        'Explanation': 'explanation.n.01',\n",
    "        'Judge': None,\n",
    "        'disgraceful.a': 'disgraceful.s.01',\n",
    "        'shameful.a': 'disgraceful.s.01'\n",
    "    },\n",
    "    'Obviousness': {\n",
    "        'Obviousness': 'obviousness.n.01',\n",
    "        'Phenomenon': 'phenomenon.n.01',\n",
    "        'Attribute': 'property.n.04',\n",
    "        'Degree': 'degree.n.01',\n",
    "        'Time': 'time.n.03',\n",
    "        'Circumstances': 'circumstance.n.01',\n",
    "        'Perceiver': 'perceiver.n.01',\n",
    "        'Evidence': 'evidence.n.02',\n",
    "        'Group': 'group.n.01',\n",
    "        'Location_of_protagonist': 'location.n.01',\n",
    "        'Particular_iteration': 'particular.s.06',\n",
    "        'Direction': 'direction.n.03',\n",
    "        'obvious.a': 'obvious.a.01',\n",
    "        'evident.a': 'apparent.s.01',\n",
    "        'manifest.a': 'apparent.s.01',\n",
    "        'visible.a': 'visible.a.01',\n",
    "        'audible.a': 'audible.a.01',\n",
    "        'unclear.a': 'unclear.a.02',\n",
    "        'clear.a': 'clear.a.01',\n",
    "        'clearly.adv': 'clearly.r.01',\n",
    "        'obviously.adv': 'obviously.r.01',\n",
    "        'clarity.n': 'clarity.n.01',\n",
    "        'show.v': 'show.v.04',\n",
    "        'show up.v': 'show.v.04',\n",
    "        'stand out.v': None,\n",
    "        'noticeable.a': 'noticeable.a.01'\n",
    "    },\n",
    "    'Infrastructure': {\n",
    "        'Infrastructure':'infrastructure.n.02',\n",
    "        'Activity':'activity.n.01',\n",
    "        'Place':'topographic_point.n.01',\n",
    "        'Possessor':'owner.n.02',\n",
    "        'Resource':'resource.n.02',\n",
    "        'User':'user.n.01',\n",
    "        'Descriptor':'descriptor.n.02',\n",
    "        'Infrastructure':'infrastructure.n.01',\n",
    "        'infrastructure.n':'infrastructure.n.01',\n",
    "        'base.n':'basis.n.02'\n",
    "    },\n",
    "    'Product_line': {\n",
    "        'Product_line': 'merchandise.n.01',\n",
    "        'Brand' : 'trade_name.n.01',\n",
    "        'Collection': 'collection.n.01',\n",
    "        'Products': 'merchandise.n.01',\n",
    "        'Descriptor': 'descriptor.n.02',\n",
    "        'Collection_name': 'collection.n.01',\n",
    "        'Designer': 'couturier.n.01',\n",
    "        'line.n': 'line.n.22',\n",
    "        'collection.n': 'collection.n.01'\n",
    "    },\n",
    "    'Gusto': {\n",
    "        'Gusto': 'gusto.n.01',\n",
    "        'Person': 'person.n.01',\n",
    "        'Degree': 'degree.n.01',\n",
    "        'life.n': 'liveliness.n.02',\n",
    "        'vim.n': 'energy.n.05',\n",
    "        'spirit.n': 'spirit.n.03'\n",
    "    },\n",
    "    'Military': {\n",
    "        'Military': 'military.n.01',\n",
    "        'Force': 'force.n.04',\n",
    "        'Possessor': 'owner.n.02',\n",
    "        'Descriptor': None,\n",
    "        'Members': 'member.n.04',\n",
    "        'Domain': 'domain.n.02',\n",
    "        'Goal': 'goal.n.01',\n",
    "        'Period_of_existence': 'time_period.n.01',\n",
    "        'military.n': 'military.n.01',\n",
    "        'force.n': 'force.n.04',\n",
    "        'navy.n': 'navy.n.01',\n",
    "        'air force.n': None,\n",
    "        'army.n': 'army.n.01',\n",
    "        'naval.a': 'naval.a.01',\n",
    "        'armed forces.n': None,\n",
    "        'military.a': 'military.a.01',\n",
    "        'military forces.n': 'military.n.01',\n",
    "        'militia.n': 'militia.n.01',\n",
    "        'national guard.n': None,\n",
    "        'marines.n': 'marines.n.01',\n",
    "        'coast guard.n': None\n",
    "    },\n",
    "    'Terrorism': {\n",
    "        'Terrorism': 'terrorism.n.01',\n",
    "        'Terrorist': 'terrorist.n.01',\n",
    "        'Act': 'act.n.02',\n",
    "        'Victim': 'victim.n.01',\n",
    "        'Organization': 'organization.n.01',\n",
    "        'Descriptor': 'descriptor.n.02',\n",
    "        'Manner': 'manner.n.01',\n",
    "        'Means': 'means.n.01',\n",
    "        'Time': 'time.n.01',\n",
    "        'Place': 'topographic_point.n.01',\n",
    "        'Purpose': 'purpose.n.01',\n",
    "        'Instrument': 'instrument.n.02',\n",
    "        'terrorism.n': 'terrorism.n.01',\n",
    "        'terrorist.n': 'terrorist.n.01',\n",
    "        'ecoterrorism [environmentalism].n': 'ecoterrorism.n.01',\n",
    "        'ecoterrorist [environmentalist].n': None,\n",
    "        'bioterrorism.n': 'bioterrorism.n.01',\n",
    "        'bioterrorist.n': None,\n",
    "        'ecoterrorist.n': None,\n",
    "        'ecoterrorism.n': 'ecoterrorism.n.01',\n",
    "        'obviously.adv': 'obviously.r.01',\n",
    "        'terror.n': 'terror.n.04'\n",
    "    }\n",
    "}\n",
    "\n",
    "result_dict = {}\n",
    "for id in ids:\n",
    "    frame = fn.frame_by_id(id)\n",
    "    result_dict[frame.name] = {}\n",
    "    frame_context = get_frame_ctx(id)\n",
    "\n",
    "    synsets = wn.synsets(frame.name.split('_')[0])\n",
    "    res_max = 0\n",
    "    best_syn = None\n",
    "    \n",
    "    for syn in synsets:\n",
    "        synset_context = get_synset_ctx(syn)\n",
    "        res = bag_of_words(frame_context, synset_context)\n",
    "        if res > res_max:\n",
    "            res_max = res\n",
    "            best_syn = syn\n",
    "    if best_syn is not None:\n",
    "        result_dict[frame.name][frame.name] = best_syn.name()\n",
    "    else:\n",
    "        result_dict[frame.name][frame.name] = None\n",
    "    \n",
    "    for fe in frame.FE:\n",
    "        res_max = 0\n",
    "        best_syn = None\n",
    "        for syn in wn.synsets(fe.split(\"_\")[0]):\n",
    "            synset_context = get_synset_ctx(syn)\n",
    "            res = bag_of_words(frame_context, synset_context)\n",
    "            if res > res_max:\n",
    "                res_max = res\n",
    "                best_syn = syn\n",
    "        if best_syn is not None:\n",
    "            result_dict[frame.name][fe] = best_syn.name()\n",
    "        else:\n",
    "            result_dict[frame.name][fe] = None\n",
    "    i = 0\n",
    "    for lu in frame.lexUnit.keys():\n",
    "        res_max = 0\n",
    "        best_syn = None\n",
    "        if i<20:\n",
    "            for syn in wn.synsets(lu.split(\".\")[0].split(\" \")[0]):\n",
    "                synset_context = get_synset_ctx(syn)\n",
    "                res = bag_of_words(frame_context, synset_context)\n",
    "                if res > res_max:\n",
    "                    res_max = res\n",
    "                    best_syn = syn\n",
    "            i += 1\n",
    "            if best_syn is not None:        \n",
    "                result_dict[frame.name][lu] = best_syn.name()\n",
    "            else:\n",
    "                result_dict[frame.name][lu] = None\n",
    "\n",
    "print(f\"La valutazione del sistema è del: {round(get_evaluation(result_dict, annotation_dict)*100, 2)}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6847c98a8f86b01c6a19c518cd2f366693b80566b266804d5ca763cbb223f52b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
