{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FrameNet API in nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "'''\n",
    "    nltk.download('all')\n",
    "o in alternativa\n",
    "    nltk.download('framenet')\n",
    "'''\n",
    "from nltk.corpus import framenet as fn\n",
    "from nltk.corpus.reader.framenet import PrettyList\n",
    "\n",
    "from operator import itemgetter\n",
    "from pprint import pprint\n",
    "import numpy as np  \n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credits\n",
    "\n",
    "- Collin F. Baker, Nathan Schneider, Miriam R. L. Petruck, and Michael Ellsworth. Tutorial *Getting the Roles Right: Using FrameNet in NLP* tenuto presso la North American Chapter of the Association for Computational Linguistics - Human Language Technology (NAACL HLT 2015), \n",
    "    - http://naacl.org/naacl-hlt-2015/tutorial-framenet.html \n",
    "- documentazione NLTK, \n",
    "    - https://www.nltk.org/api/nltk.corpus.reader.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentazione all'URL [https://www.nltk.org/api/nltk.corpus.reader.html](https://www.nltk.org/api/nltk.corpus.reader.html)\n",
    "\n",
    "- nltk.corpus.reader.framenet module, Corpus reader for the FrameNet 1.7 lexicon and corpus.\n",
    "\n",
    "#### API Entry Points \n",
    "```\n",
    "    frames([nameRegex])\n",
    "    frame(exactName)\n",
    "    frames_by_lemma(lemmaRegex)\n",
    "\n",
    "    lus([nameRegex])\n",
    "    fes([nameRegex])\n",
    "\n",
    "    semtypes()\n",
    "    propagate_semtypes()\n",
    "\n",
    "    frame_relations([frame, [frame2,]] [type]) frame_relation_types()\n",
    "    fe_relations()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretty{List,Dict}\n",
    "```\n",
    "    >>> fn.frames('noise')\n",
    "    [<frame ID=801 name=Cause_to_make_noise>, <frame ID=60 name=Motion_noise>, ...]\n",
    "    >>> type(fn.frames('noise'))\n",
    "    <class 'nltk.corpus.reader.framenet.PrettyList'>\n",
    "```\n",
    "\n",
    "PrettyList does 2 things: \n",
    "- limits the number of elements shown, and suppresses printing of their full details\n",
    "    - Otherwise, it is just a list\n",
    "- Similarly, PrettyDict suppresses printing of its values' details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fn.frames(r'(?i)medical'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fn.frames('Medical_specialties'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = fn.frame(256)\n",
    "f.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_sep():\n",
    "    print('\\n_________________________________________________________\\n\\n')\n",
    "\n",
    "f = fn.frame_by_name('Medical_specialties')\n",
    "print(f)\n",
    "print_sep()\n",
    "print(fn.frame_by_name('Perception'))\n",
    "print_sep()\n",
    "print(fn.frame_by_name('Complaining'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Struttura interna del frame\n",
    "\n",
    "The dict that is returned from the `frame` function will contain the\n",
    "        following information about the Frame:\n",
    "\n",
    "        - 'name'       : the name of the Frame (e.g. 'Birth', 'Apply_heat', etc.)\n",
    "        - 'definition' : textual definition of the Frame\n",
    "        - 'ID'         : the internal ID number of the Frame\n",
    "        - 'semTypes'   : a list of semantic types for this frame\n",
    "           - Each item in the list is a dict containing the following keys:\n",
    "              - 'name' : can be used with the semtype() function\n",
    "              - 'ID'   : can be used with the semtype() function\n",
    "\n",
    "        - 'lexUnit'    : a dict containing all of the LUs for this frame.\n",
    "                         The keys in this dict are the names of the LUs and\n",
    "                         the value for each key is itself a dict containing\n",
    "                         info about the LU (see the lu() function for more info.)\n",
    "\n",
    "        - 'FE' : a dict containing the Frame Elements that are part of this frame\n",
    "                 The keys in this dict are the names of the FEs (e.g. 'Body_system')\n",
    "                 and the values are dicts containing the following keys\n",
    "              - 'definition' : The definition of the FE\n",
    "              - 'name'       : The name of the FE e.g. 'Body_system'\n",
    "              - 'ID'         : The id number\n",
    "              - '_type'      : 'fe'\n",
    "              - 'abbrev'     : Abbreviation e.g. 'bod'\n",
    "              - 'coreType'   : one of \"Core\", \"Peripheral\", or \"Extra-Thematic\"\n",
    "              - 'semType'    : if not None, a dict with the following two keys:\n",
    "                 - 'name' : name of the semantic type. can be used with\n",
    "                            the semtype() function\n",
    "                 - 'ID'   : id number of the semantic type. can be used with\n",
    "                            the semtype() function\n",
    "              - 'requiresFE' : if not None, a dict with the following two keys:\n",
    "                 - 'name' : the name of another FE in this frame\n",
    "                 - 'ID'   : the id of the other FE in this frame\n",
    "              - 'excludesFE' : if not None, a dict with the following two keys:\n",
    "                 - 'name' : the name of another FE in this frame\n",
    "                 - 'ID'   : the id of the other FE in this frame\n",
    "\n",
    "        - 'frameRelation'      : a list of objects describing frame relations\n",
    "        - 'FEcoreSets'  : a list of Frame Element core sets for this frame\n",
    "           - Each item in the list is a list of FE objects\n",
    "\n",
    "        :param fn_fid_or_fname: The Framenet name or id number of the frame\n",
    "        :type fn_fid_or_fname: int or str\n",
    "        :param ignorekeys: The keys to ignore. These keys will not be\n",
    "            included in the output. (optional)\n",
    "        :type ignorekeys: list(str)\n",
    "        :return: Information about a frame\n",
    "        :rtype: dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f)\n",
    "print_sep()\n",
    "# print(len(f.lexUnit))\n",
    "# print(sorted([x for x in f.lexUnit]))\n",
    "print_sep()\n",
    "print(sorted([x for x in f.FE]))\n",
    "print_sep()\n",
    "print(f.frameRelations)\n",
    "print_sep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also search for Frames by their Lexical Units (LUs). The **frames_by_lemma()** function returns a list of all frames that contain LUs in which the 'name' attribute of the LU matches the given regular expression. Note that LU names are composed of \"lemma.POS\", where the \"lemma\" part can be made up of either a single lexeme (e.g. 'run') or multiple lexemes (e.g. 'a little') (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fn.frames_by_lemma(r'(?i)epidemiol'))\n",
    "print(fn.frames_by_lemma(r'(?i)accident'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame_list = PrettyList(fn.frames(r'(?i)crim'), maxReprSize=0, breakLines=True)\n",
    "frame_list.sort(key=itemgetter('ID'))\n",
    "\n",
    "for f in frame_list:\n",
    "    print('======================\\nNAME: ' + str(f.name))\n",
    "    print('======================\\nDEF:  ' + str(f.definition))\n",
    "    print('======================\\nFEs:  ' + str(f.FE))\n",
    "#     print('======================\\nLUs:  ' + str(f.lexUnit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Also see the ``frame()`` function for details about what is\n",
    "    contained in the dict that is returned.\n",
    "\"\"\"\n",
    "\n",
    "f = fn.frame_by_id(256)\n",
    "\n",
    "print('NAME: {}[{}]\\tDEF: {}'.format(f.name, f.ID, f.definition))\n",
    "\n",
    "print('\\n____ FEs ____')\n",
    "FEs = f.FE.keys()\n",
    "for fe in FEs:\n",
    "    fed = f.FE[fe]\n",
    "    print('\\tFE: {}\\tDEF: {}'.format(fe, fed.definition))\n",
    "    # print(fed.definition)\n",
    "    \n",
    "print('\\n____ LUs ____')\n",
    "LUs = f.lexUnit.keys()\n",
    "for lu in LUs:\n",
    "    print(lu)\n",
    "\n",
    "#    print('\\tFE-DEF: ' + fe.definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical Units\n",
    "\n",
    "A lexical unit (LU) is a pairing of a word with a meaning. For example, the \"Apply_heat\" Frame describes a common situation involving a Cook, some Food, and a Heating Instrument, and is _evoked_ by words such as bake, blanch, boil, broil, brown, simmer, steam, etc. These frame-evoking words are the LUs in the Apply_heat frame. Each sense of a polysemous word is a different LU.\n",
    "\n",
    "We have used the word \"word\" in talking about LUs. The reality is actually rather complex. When we say that the word \"bake\" is polysemous, we mean that the lemma \"bake.v\" (which has the word-forms \"bake\", \"bakes\", \"baked\", and \"baking\") is linked to three different frames:\n",
    "\n",
    "- Apply_heat: \"Michelle baked the potatoes for 45 minutes.\"\n",
    "- Cooking_creation: \"Michelle baked her mother a cake for her birthday.\"\n",
    "- Absorb_heat: \"The potatoes have to bake for more than 30 minutes.\"\n",
    "\n",
    "These constitute three different LUs, with different definitions.\n",
    "\n",
    "Framenet provides multiple annotated examples of each sense of a word (i.e. each LU). Moreover, the set of examples (approximately 20 per LU) illustrates all of the combinatorial possibilities of the lexical unit.\n",
    "\n",
    "Each LU is linked to a Frame, and hence to the other words which evoke that Frame. This makes the FrameNet database similar to a thesaurus, grouping together semantically similar words.\n",
    "\n",
    "In the simplest case, frame-evoking words are verbs such as \"fried\" in:\n",
    "\n",
    "\"Matilde fried the catfish in a heavy iron skillet.\"\n",
    "Sometimes event nouns may evoke a Frame. For example, \"reduction\" evokes \"Cause_change_of_scalar_position\" in:\n",
    "\n",
    "\"...the reduction of debt levels to $665 million from $2.6 billion.\"\n",
    "Adjectives may also evoke a Frame. For example, \"asleep\" may evoke the \"Sleep\" frame as in:\n",
    "\n",
    "\"They were asleep for hours.\"\n",
    "\n",
    "Many common nouns, such as artifacts like \"hat\" or \"tower\", typically serve as dependents rather than clearly evoking their own frames.\n",
    "\n",
    "Details for a specific lexical unit can be obtained using this class's lus() function, which takes an optional regular expression pattern that will be matched against the name of the lexical unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fn.lus(r'(?i)a little'))\n",
    "print(fn.lus(r'foresee'))\n",
    "\n",
    "print(fn.frames_by_lemma(r'(?i)little'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "quante LUs sono presenti in FN??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fn.lus()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consideriamo la LU di `foresee.v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fn.lu(256).frame.name)\n",
    "print(fn.lu(256).definition)\n",
    "print(fn.lu(256).lexemes[0].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Vendetta!\n",
    "\n",
    "Immaginiamo di accedere al frame 'Revenge'. Prima visualizziamo tutto il suo contenuto, e poi accediamo a Frame Elements (FEs) e Lexical Units (LUs).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = fn.frame('Revenge')\n",
    "\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f.FE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è possibile inoltre accedere selettivamente alla definzione associata a un certo FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.FE['Injury'].definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "elenco delle LUs del frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.lexUnit.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selezione di tutti i frame che hanno un FE che ha a che fare con 'location':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.fes('location')\n",
    "\n",
    "{fe.name for fe in fn.fes(\"location\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e per ciascuno dei FEs che ha a che fare con 'location' possiamo risalire al relativo Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fe in fn.fes(\"location\"):\n",
    "    print(fe.frame.name + '.' + fe.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame relations\n",
    "\n",
    "Elenco delle possibili relazioni fra frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import sys\n",
    "\n",
    "def get_fn_relations(fn_rel_list):\n",
    "    frame_rels = []\n",
    "\n",
    "    for f in fn_rel_list:\n",
    "        text = str(f)\n",
    "        try:\n",
    "            found = re.search('.*-- (.+?) ->.*', text).group(1)\n",
    "            # print(found)\n",
    "            frame_rels.append(found)\n",
    "        except AttributeError:\n",
    "            print('the expression \\n\\t{}\\n does not contain the searched pattern'.format(f))\n",
    "            sys.exit(1)\n",
    "    \n",
    "    # rels_set = set(frame_rels)\n",
    "    # print(rels_set)\n",
    "    return set(frame_rels)\n",
    "\n",
    "fn_rels = get_fn_relations(fn.frame_relations())\n",
    "for fr in fn_rels:\n",
    "    print('\\t' + fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibile utilizzo: che cosa viene causato da 'Make_noise'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.frame_relations(frame='Make_noise', type='Causative_of')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e più in generale, con quali altri frame è in relazione '`Make_noise`'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rels = fn.frame_relations(frame='Make_noise')\n",
    "for rel in rels:\n",
    "    print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Accesso alle **annotazioni**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_term = 'revenge'\n",
    "count = 0\n",
    "\n",
    "while count < 10:\n",
    "    print(fn.exemplars(input_term)[count].FE)\n",
    "    # print(fn.exemplars(input_term)[count].POS)\n",
    "    print(fn.exemplars(input_term)[count].annotationSet[0])\n",
    "    count += 1\n",
    "    print_sep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### getFrameSetForStudent\n",
    "\n",
    "Funzione per assegnare a ciascuno un insieme di frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import random\n",
    "from random import randint\n",
    "from random import seed\n",
    "\n",
    "def print_frames_with_IDs():\n",
    "    for x in fn.frames():\n",
    "        print('{}\\t{}'.format(x.ID, x.name))\n",
    "\n",
    "def get_frams_IDs():\n",
    "    return [f.ID for f in fn.frames()]   \n",
    "\n",
    "def getFrameSetForStudent(surname, list_len=5):\n",
    "    nof_frames = len(fn.frames())\n",
    "    base_idx = (abs(int(hashlib.sha512(surname.encode('utf-8')).hexdigest(), 16)) % nof_frames)\n",
    "    print('\\nstudent: ' + surname)\n",
    "    framenet_IDs = get_frams_IDs()\n",
    "    i = 0\n",
    "    offset = 0 \n",
    "    seed(1)\n",
    "    while i < list_len:\n",
    "        fID = framenet_IDs[(base_idx+offset)%nof_frames]\n",
    "        f = fn.frame(fID)\n",
    "        fNAME = f.name\n",
    "        print('\\tID: {a:4d}\\tframe: {framename}'.format(a=fID, framename=fNAME))\n",
    "        offset = randint(0, nof_frames)\n",
    "        i += 1        \n",
    "\n",
    "\n",
    "getFrameSetForStudent('LuCIAnI')\n",
    "getFrameSetForStudent('FanCELlu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metodi utili per fare pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(text):\n",
    "    result = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word in text:\n",
    "        result.append(lemmatizer.lemmatize(word))\n",
    "    return result\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    return re.sub(r'[^\\w\\s]', '', s)\n",
    "\n",
    "def remove_stop_words(row):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_sentence = [w for w in row if not w.lower() in stop_words]\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Id dei frame estratti "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [2724, 244, 5, 1612, 1360, 1481, 2524, 2569, 1514, 1750]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per ciascun Frame assegno un WN synset a:\n",
    "    1. Frame Name\n",
    "    2. Frame Elements (FEs)\n",
    "    3. Lexical Units (LUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synset_from_frames(index):\n",
    "    frame_name = fn.frame_by_id(index).name\n",
    "    return wn.synsets(frame_name.split('_')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estrapolazione del contesto dal synset\n",
    "Obiettivo è creare una lista che contenga i termini rilevanti per creare un contesto del synset. I termini rilevanti sono all'interno di:\n",
    "- definizione del synset;\n",
    "- esempi del synset;\n",
    "- lemmi;\n",
    "- definizioni di iponimi e iperonimi.\n",
    "- esempi di iponimi e iperonimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synset_ctx(synset):\n",
    "    defs = remove_punctuation(synset.definition())\n",
    "    exs = remove_punctuation(' '.join(synset.examples()))\n",
    "    defs = remove_stop_words(lemmatize_words(defs.split()))\n",
    "    exs = remove_stop_words(lemmatize_words(exs.split()))\n",
    "\n",
    "    hypo = synset.hyponyms()\n",
    "    hyper = synset.hypernyms()\n",
    "    lemmas = synset.lemmas()\n",
    "    \n",
    "    lems = []\n",
    "    for l in lemmas:\n",
    "        lems = lems + l.name().split(\"_\")\n",
    "\n",
    "    for h in hypo:\n",
    "        defs = defs + remove_stop_words(lemmatize_words(remove_punctuation(h.definition()).split()))\n",
    "        exs = exs + remove_stop_words(lemmatize_words(remove_punctuation(' '.join(h.examples())).split()))\n",
    "    \n",
    "    for h in hyper:\n",
    "        defs = defs + remove_stop_words(lemmatize_words(remove_punctuation(h.definition()).split()))\n",
    "        exs = exs + remove_stop_words(lemmatize_words(remove_punctuation(' '.join(h.examples())).split()))\n",
    "\n",
    "    return defs + exs + lems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estrapolazione del contesto dal frame\n",
    "Obiettivo è creare una lista che contenga i termini rilevanti per creare un contesto del frame. I termini rilevanti sono presi sia dalla definizione del frame sia dalla definizione dei FEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_ctx(id):\n",
    "    ctx = []\n",
    "    frame = fn.frame_by_id(id)\n",
    "    ctx = ctx + frame.name.split(' ')\n",
    "    defs = remove_punctuation(frame.definition)\n",
    "    defs = remove_stop_words(defs.split(\" \"))\n",
    "    ctx = ctx + lemmatize_words(defs)\n",
    "    \n",
    "    for fe in frame.FE:\n",
    "        fe_defs = remove_punctuation(frame.FE[fe].definition)\n",
    "        fe_defs = remove_stop_words(fe_defs.split(\" \"))\n",
    "        ctx = ctx + lemmatize_words(fe_defs)\n",
    "    return ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approccio Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(frame_context, synset_context):\n",
    "    return len([word for word in frame_context if word in synset_context]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation(result_dict, annotation_dict):\n",
    "    count_eval = 0\n",
    "    len_total = 0\n",
    "    for k in result_dict.keys():\n",
    "        len_total += len(result_dict[k].keys())\n",
    "        for el in result_dict[k].keys():\n",
    "            if result_dict[k][el] == annotation_dict[k][el]:\n",
    "                count_eval += 1\n",
    "\n",
    "    return count_eval / len_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La valutazione del sistema è del: 49.67%\n"
     ]
    }
   ],
   "source": [
    "annotation_dict = {\n",
    "    'Chemical_potency': {\n",
    "        'Chemical_potency':'chemical.n.01',\n",
    "        'Chemical_entity':'chemical.n.01',\n",
    "        'Degree':'degree.n.02',\n",
    "        'Time':'time.n.03',\n",
    "        'Circumstances':'circumstance.n.01',\n",
    "        'Place':'place.n.02',\n",
    "        'strong.a':'strong.a.01',\n",
    "        'potent.a':'potent.s.02',\n",
    "        'stiff.a':'potent.a.03'\n",
    "    },\n",
    "    'Fullness': {\n",
    "        'Fullness': 'fullness.n.03',\n",
    "        'Container' : 'container.n.01',\n",
    "        'Contents': 'content.n.01',\n",
    "        'Degree': 'degree.n.01',\n",
    "        'Time': 'time.n.03',\n",
    "        'Frequency': 'frequency.n.01',\n",
    "        'Duration': 'duration.n.01',\n",
    "        'full.a': 'full.a.01',\n",
    "        'empty.a': 'empty.a.01',\n",
    "        'emptiness.n': 'emptiness.n.01',\n",
    "        'fullness.n': 'fullness.n.03'\n",
    "    },\n",
    "    'Causation': {\n",
    "        'Causation': 'causing.n.01',\n",
    "        'Cause': 'cause.n.01',\n",
    "        'Affected': 'affected.a.01',\n",
    "        'Effect': 'consequence.n.01',\n",
    "        'Place': 'place.n.02',\n",
    "        'Time': 'time.n.03',\n",
    "        'Actor': 'actor.n.02',\n",
    "        'Circumstances': 'context.n.02',\n",
    "        'Manner': 'manner.n.01',\n",
    "        'Explanation': 'explanation.n.01',\n",
    "        'Means': 'means.n.01',\n",
    "        'Frequency': 'frequency.n.01',\n",
    "        'Concessive': 'concessive.a.01',\n",
    "        'cause.v':'cause.v.01',\n",
    "        'cause.n':'cause.n.01',\n",
    "        'make.v':'make.v.03',\n",
    "        'lead (to).v':'lead.v.03',\n",
    "        'reason.n':'cause.n.02',\n",
    "        'send.v':'send.v.01',\n",
    "        'bring about.v':'bring.v.03',\n",
    "        'precipitate.v':'precipitate.v.01',\n",
    "        'causative.a':'causative.a.1',\n",
    "        'render.v':'render.v.01',\n",
    "        'bring.v':'bring.v.02',\n",
    "        'bring on.v':'bring.v.02',\n",
    "        'induce.v':'induce.v.01',\n",
    "        'wreak.v':'bring.v.03',\n",
    "        'put.v':'put.v.02',\n",
    "        'since.c': None,\n",
    "        'because.c': None,\n",
    "        'because of.prep': None,\n",
    "        'raise.v':'raise.v.03',\n",
    "        'result (in).v':'result.v.01'\n",
    "    },\n",
    "    'Disgraceful_situation': {\n",
    "        'Disgraceful_situation': 'disgraceful.s.01',\n",
    "        'State_of_affairs': 'state.n.02',\n",
    "        'Protagonist': 'protagonist.n.02',\n",
    "        'Degree': 'degree.n.01',\n",
    "        'Explanation': 'explanation.n.01',\n",
    "        'Judge': None,\n",
    "        'disgraceful.a': 'disgraceful.s.01',\n",
    "        'shameful.a': 'disgraceful.s.01'\n",
    "    },\n",
    "    'Obviousness': {\n",
    "        'Obviousness': 'obviousness.n.01',\n",
    "        'Phenomenon': 'phenomenon.n.01',\n",
    "        'Attribute': 'property.n.04',\n",
    "        'Degree': 'degree.n.01',\n",
    "        'Time': 'time.n.03',\n",
    "        'Circumstances': 'circumstance.n.01',\n",
    "        'Perceiver': 'perceiver.n.01',\n",
    "        'Evidence': 'evidence.n.02',\n",
    "        'Group': 'group.n.01',\n",
    "        'Location_of_protagonist': 'location.n.01',\n",
    "        'Particular_iteration': 'particular.s.06',\n",
    "        'Direction': 'direction.n.03',\n",
    "        'obvious.a': 'obvious.a.01',\n",
    "        'evident.a': 'apparent.s.01',\n",
    "        'manifest.a': 'apparent.s.01',\n",
    "        'visible.a': 'visible.a.01',\n",
    "        'audible.a': 'audible.a.01',\n",
    "        'unclear.a': 'unclear.a.02',\n",
    "        'clear.a': 'clear.a.01',\n",
    "        'clearly.adv': 'clearly.r.01',\n",
    "        'obviously.adv': 'obviously.r.01',\n",
    "        'clarity.n': 'clarity.n.01',\n",
    "        'show.v': 'show.v.04',\n",
    "        'show up.v': 'show.v.04',\n",
    "        'stand out.v': None,\n",
    "        'noticeable.a': 'noticeable.a.01'\n",
    "    },\n",
    "    'Infrastructure': {\n",
    "        'Infrastructure':'infrastructure.n.02',\n",
    "        'Activity':'activity.n.01',\n",
    "        'Place':'topographic_point.n.01',\n",
    "        'Possessor':'owner.n.02',\n",
    "        'Resource':'resource.n.02',\n",
    "        'User':'user.n.01',\n",
    "        'Descriptor':'descriptor.n.02',\n",
    "        'Infrastructure':'infrastructure.n.01',\n",
    "        'infrastructure.n':'infrastructure.n.01',\n",
    "        'base.n':'basis.n.02'\n",
    "    },\n",
    "    'Product_line': {\n",
    "        'Product_line': 'merchandise.n.01',\n",
    "        'Brand' : 'trade_name.n.01',\n",
    "        'Collection': 'collection.n.01',\n",
    "        'Products': 'merchandise.n.01',\n",
    "        'Descriptor': 'descriptor.n.02',\n",
    "        'Collection_name': 'collection.n.01',\n",
    "        'Designer': 'couturier.n.01',\n",
    "        'line.n': 'line.n.22',\n",
    "        'collection.n': 'collection.n.01'\n",
    "    },\n",
    "    'Gusto': {\n",
    "        'Gusto': 'gusto.n.01',\n",
    "        'Person': 'person.n.01',\n",
    "        'Degree': 'degree.n.01',\n",
    "        'life.n': 'liveliness.n.02',\n",
    "        'vim.n': 'energy.n.05',\n",
    "        'spirit.n': 'spirit.n.03'\n",
    "    },\n",
    "    'Military': {\n",
    "        'Military': 'military.n.01',\n",
    "        'Force': 'force.n.04',\n",
    "        'Possessor': 'owner.n.02',\n",
    "        'Descriptor': None,\n",
    "        'Members': 'member.n.04',\n",
    "        'Domain': 'domain.n.02',\n",
    "        'Goal': 'goal.n.01',\n",
    "        'Period_of_existence': 'time_period.n.01',\n",
    "        'military.n': 'military.n.01',\n",
    "        'force.n': 'force.n.04',\n",
    "        'navy.n': 'navy.n.01',\n",
    "        'air force.n': None,\n",
    "        'army.n': 'army.n.01',\n",
    "        'naval.a': 'naval.a.01',\n",
    "        'armed forces.n': None,\n",
    "        'military.a': 'military.a.01',\n",
    "        'military forces.n': 'military.n.01',\n",
    "        'militia.n': 'militia.n.01',\n",
    "        'national guard.n': None,\n",
    "        'marines.n': 'marines.n.01',\n",
    "        'coast guard.n': None\n",
    "    },\n",
    "    'Terrorism': {\n",
    "        'Terrorism': 'terrorism.n.01',\n",
    "        'Terrorist': 'terrorist.n.01',\n",
    "        'Act': 'act.n.02',\n",
    "        'Victim': 'victim.n.01',\n",
    "        'Organization': 'organization.n.01',\n",
    "        'Descriptor': 'descriptor.n.02',\n",
    "        'Manner': 'manner.n.01',\n",
    "        'Means': 'means.n.01',\n",
    "        'Time': 'time.n.01',\n",
    "        'Place': 'topographic_point.n.01',\n",
    "        'Purpose': 'purpose.n.01',\n",
    "        'Instrument': 'instrument.n.02',\n",
    "        'terrorism.n': 'terrorism.n.01',\n",
    "        'terrorist.n': 'terrorist.n.01',\n",
    "        'ecoterrorism [environmentalism].n': 'ecoterrorism.n.01',\n",
    "        'ecoterrorist [environmentalist].n': None,\n",
    "        'bioterrorism.n': 'bioterrorism.n.01',\n",
    "        'bioterrorist.n': None,\n",
    "        'ecoterrorist.n': None,\n",
    "        'ecoterrorism.n': 'ecoterrorism.n.01',\n",
    "        'obviously.adv': 'obviously.r.01',\n",
    "        'terror.n': 'terror.n.04'\n",
    "    }\n",
    "}\n",
    "\n",
    "result_dict = {}\n",
    "for id in ids:\n",
    "    frame = fn.frame_by_id(id)\n",
    "    result_dict[frame.name] = {}\n",
    "    frame_context = get_frame_ctx(id)\n",
    "    synsets = get_synset_from_frames(id)\n",
    "    res_max = 0\n",
    "    best_syn = None\n",
    "    \n",
    "    for syn in synsets:\n",
    "        synset_context = get_synset_ctx(syn)\n",
    "        res = bag_of_words(frame_context, synset_context)\n",
    "        if res > res_max:\n",
    "            res_max = res\n",
    "            best_syn = syn\n",
    "    if best_syn is not None:\n",
    "        result_dict[frame.name][frame.name] = best_syn.name()\n",
    "    else:\n",
    "        result_dict[frame.name][frame.name] = None\n",
    "    \n",
    "    for fe in frame.FE:\n",
    "        res_max = 0\n",
    "        best_syn = None\n",
    "        for syn in wn.synsets(fe.split(\"_\")[0]):\n",
    "            synset_context = get_synset_ctx(syn)\n",
    "            res = bag_of_words(frame_context, synset_context)\n",
    "            if res > res_max:\n",
    "                res_max = res\n",
    "                best_syn = syn\n",
    "        if best_syn is not None:\n",
    "            result_dict[frame.name][fe] = best_syn.name()\n",
    "        else:\n",
    "            result_dict[frame.name][fe] = None\n",
    "    i = 0\n",
    "    for lu in frame.lexUnit.keys():\n",
    "        res_max = 0\n",
    "        best_syn = None\n",
    "        if i<20:\n",
    "            for syn in wn.synsets(lu.split(\".\")[0].split(\" \")[0]):\n",
    "                synset_context = get_synset_ctx(syn)\n",
    "                res = bag_of_words(frame_context, synset_context)\n",
    "                if res > res_max:\n",
    "                    res_max = res\n",
    "                    best_syn = syn\n",
    "            i += 1\n",
    "            if best_syn is not None:        \n",
    "                result_dict[frame.name][lu] = best_syn.name()\n",
    "            else:\n",
    "                result_dict[frame.name][lu] = None\n",
    "\n",
    "print(f\"La valutazione del sistema è del: {round(get_evaluation(result_dict, annotation_dict)*100, 2)}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('spacy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3525effbb77994477fa12acef781f772c9be5a5a62ddcd46b88c81c6046781ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
