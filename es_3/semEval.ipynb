{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_VAL = r'/home/fazza/Documents/TLN-LAB-PART-2/resources/annotations_fabio_andrea.txt'\n",
    "PATH_SYN = r'/home/fazza/Documents/TLN-LAB-PART-2/resources/babel_synset.txt'\n",
    "PATH_NASARI = r'/home/fazza/Documents/TLN-LAB-PART-2/resources/mini_NASARI.tsv'\n",
    "PATH_SEM = r'/home/fazza/Documents/TLN-LAB-PART-2/resources/SemEval17_IT_senses2synsets.txt' \n",
    "\n",
    "KEY = '5da132f9-c606-4832-9a4f-3c2e3f739cf7'\n",
    "KEY2 = 'd4bc0872-d933-4516-b456-2063fa7d68ff'\n",
    "URL = 'https://babelnet.io/v7/getSynset?id={}&key={}&targetLang=IT&searchLang=IT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recupero risorse da files\n",
    "Vengono salvati i dati delle nostre annotazioni (sia le valutazioni, sia in synset) in delle liste e vengono recuperate anche le parole da analizzare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synsets_from_txt(path):\n",
    "    andrea_list = []\n",
    "    fabio_list = []\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            andrea_list.append(line.split('    ')[2].strip('\\n'))\n",
    "            andrea_list.append(line.split('    ')[3].strip('\\n'))\n",
    "            fabio_list.append(line.split('    ')[4].strip('\\n'))\n",
    "            fabio_list.append(line.split('    ')[5].strip('\\n'))\n",
    "    \n",
    "    return andrea_list, fabio_list\n",
    "\n",
    "def get_valutation_from_txt(path):\n",
    "    andrea_list = []\n",
    "    fabio_list = []\n",
    "    mean_list = []\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            andrea_list.append(float(line.split('    ')[2]))\n",
    "            fabio_list.append(float(line.split('    ')[3]))\n",
    "            mean_list.append(float(line.split('    ')[4]))\n",
    "\n",
    "    return andrea_list, fabio_list, mean_list\n",
    "\n",
    "def get_words_from_txt(path):\n",
    "    list_of_words = []\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            list_of_words.append((line.split('    ')[0],line.split('    ')[1]))\n",
    "    return list_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recupero vettori di NASARI\n",
    "Viene salvato il file con i vettori NASARI all'interno di un dizionario che ha come chiavi il babelId e come valori gli elementi del vettore associato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nasari_to_dict(path):\n",
    "    nasari_dict = {}\n",
    "    with open(path, 'r', encoding=\"utf8\") as file:\n",
    "        for line in file.readlines():\n",
    "            splitted_line = line.split('\\t')\n",
    "            nasari_dict[splitted_line[0].split('__')[0]] = splitted_line[1:]\n",
    "            \n",
    "    return nasari_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = get_words_from_txt(PATH_VAL)\n",
    "nasari_dict = nasari_to_dict(PATH_NASARI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recupero synset da SemEval17_IT_senses2synsets.txt\n",
    "Da file recupero ogni possibile babelId associato al nostro termine da valutare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_babel_syns(word, path):\n",
    "    babel_list = []\n",
    "    flag = False\n",
    "    with open(path, 'r', encoding=\"utf8\") as file: \n",
    "        for line in file.readlines():\n",
    "            if word in line:\n",
    "                flag = True\n",
    "            elif flag and line[0] != '#':\n",
    "                babel_list.append(line)\n",
    "            else:\n",
    "                flag = False\n",
    "    return babel_list                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcolo similarità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(vec1, vec2):\n",
    "    return 1 - spatial.distance.cosine(vec1, vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcolo il massimo tra i valori di similarità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nasari_valutation(syn1, syn2, nasari_dict):\n",
    "    max = 0.0\n",
    "    max_elem = (None, None)\n",
    "    for s1 in syn1:\n",
    "        for s2 in syn2:\n",
    "            if s1.strip('\\n') in nasari_dict.keys() and s2.strip('\\n') in nasari_dict.keys():\n",
    "                test1 = list(map(float, nasari_dict[s1.strip('\\n')]))\n",
    "                test2 = list(map(float, nasari_dict[s2.strip('\\n')]))\n",
    "                sim = cos_sim(test1, test2)\n",
    "                if sim > max:\n",
    "                    max = sim\n",
    "                    max_elem = (s1.strip('\\n'), s2.strip('\\n'))\n",
    "    return max, max_elem\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valutazione accuratezza del sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sense_valutation(user_syn, system_syn):\n",
    "    i = 0\n",
    "    unit_score = 0\n",
    "    couple_score = 0\n",
    "    for syn in system_syn:\n",
    "        if syn[0] in user_syn:\n",
    "            unit_score += 1\n",
    "        if syn[1] in user_syn:\n",
    "            unit_score += 1\n",
    "            \n",
    "    for syn in system_syn:\n",
    "        if syn[0] == user_syn[i] and syn[1] == user_syn[i+1]:\n",
    "            couple_score += 1 \n",
    "        i += 2\n",
    "    return f\"elementi singoli: {unit_score/100}, coppie: {couple_score/50}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recupero termini affini da BabelNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terms_by_babel_id(babel_id):\n",
    "    res = []\n",
    "    x = requests.get(URL.format(babel_id,KEY))\n",
    "    if x.status_code != 400:\n",
    "        s = x.json()['senses']\n",
    "        for sense in s:\n",
    "            res.append(sense['properties']['fullLemma'])   \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult(res):\n",
    "    return res*4\n",
    "\n",
    "result = []\n",
    "result_elem = []\n",
    "andrea_syn, fabio_syn = get_synsets_from_txt(PATH_SYN)\n",
    "andrea_val, fabio_val, mean_val = get_valutation_from_txt(PATH_VAL)\n",
    "\n",
    "print(\"INIZIO CONSEGNA 1\")\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "print(f\"\\nCorrelazione di Spearman tra annotatori: {stats.spearmanr(andrea_val, fabio_val).correlation}\\n\")\n",
    "print(f\"\\nCorrelazione di Pearson tra annotatori: {stats.pearsonr(andrea_val, fabio_val)}\\n\")\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "for tuple in words:\n",
    "    syn_1 = get_babel_syns(tuple[0], PATH_SEM)\n",
    "    syn_2 = get_babel_syns(tuple[1], PATH_SEM)\n",
    "    \n",
    "    sim_max, elements = get_nasari_valutation(syn_1, syn_2, nasari_dict)\n",
    "    \n",
    "    result.append(sim_max)\n",
    "    result_elem.append(elements)\n",
    "\n",
    "\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "print(f\"\\nCorrelazione di Spearman tra media annotatori e sistema: {stats.spearmanr(result, mean_val).correlation}\\n\")\n",
    "print(f\"\\nCorrelazione di Pearson tra media annotatori e sistema: {stats.pearsonr(result, mean_val)}\\n\")\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "print(\"INIZIO CONSEGNA 2\")\n",
    "\n",
    "print(f\"\\nPunteggio Kappa di Cohen tra annotatori: {cohen_kappa_score(andrea_syn, fabio_syn)}\\n\")\n",
    "\n",
    "for elements in result_elem:\n",
    "    print(f\"{tuple}, {elements}, {list(dict.fromkeys(get_terms_by_babel_id(elements[0])))}, {list(dict.fromkeys(get_terms_by_babel_id(elements[1])))}\\n\")\n",
    "\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "print(f\"Accuratezza tra sistema e annotazione di Andrea: {get_sense_valutation(andrea_syn, result_elem)}\")\n",
    "print(f\"Accuratezza tra sistema e annotazione di Fabio: {get_sense_valutation(fabio_syn, result_elem)}\")\n",
    "print(\"---------------------------------------------------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('spacy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3525effbb77994477fa12acef781f772c9be5a5a62ddcd46b88c81c6046781ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
