{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_VAL = r'..\\resources\\annotations_fabio_andrea.txt'\n",
    "PATH_SYN = r'../resources/babel_synset.txt'\n",
    "PATH_NASARI = r'../resources/mini_NASARI.tsv'\n",
    "PATH_SEM = r'../resources/SemEval17_IT_senses2synsets.txt' \n",
    "\n",
    "KEY = '5da132f9-c606-4832-9a4f-3c2e3f739cf7'\n",
    "KEY2 = 'd4bc0872-d933-4516-b456-2063fa7d68ff'\n",
    "URL = 'https://babelnet.io/v7/getSynset?id={}&key={}&targetLang=IT&searchLang=IT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recupero risorse da files\n",
    "Vengono salvati i dati delle nostre annotazioni (sia le valutazioni, sia in synset) in delle liste e vengono recuperate anche le parole da analizzare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synsets_from_txt(path):\n",
    "    andrea_list = []\n",
    "    fabio_list = []\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            andrea_list.append(line.split('    ')[2].strip('\\n'))\n",
    "            andrea_list.append(line.split('    ')[3].strip('\\n'))\n",
    "            fabio_list.append(line.split('    ')[4].strip('\\n'))\n",
    "            fabio_list.append(line.split('    ')[5].strip('\\n'))\n",
    "    \n",
    "    return andrea_list, fabio_list\n",
    "\n",
    "def get_valutation_from_txt(path):\n",
    "    andrea_list = []\n",
    "    fabio_list = []\n",
    "    mean_list = []\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            andrea_list.append(float(line.split('    ')[2]))\n",
    "            fabio_list.append(float(line.split('    ')[3]))\n",
    "            mean_list.append(float(line.split('    ')[4]))\n",
    "\n",
    "    return andrea_list, fabio_list, mean_list\n",
    "\n",
    "def get_words_from_txt(path):\n",
    "    list_of_words = []\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            list_of_words.append((line.split('    ')[0],line.split('    ')[1]))\n",
    "    return list_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recupero vettori di NASARI\n",
    "Viene salvato il file con i vettori NASARI all'interno di un dizionario che ha come chiavi il babelId e come valori gli elementi del vettore associato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nasari_to_dict(path):\n",
    "    nasari_dict = {}\n",
    "    with open(path, 'r', encoding=\"utf8\") as file:\n",
    "        for line in file.readlines():\n",
    "            splitted_line = line.split('\\t')\n",
    "            nasari_dict[splitted_line[0].split('__')[0]] = splitted_line[1:]\n",
    "            \n",
    "    return nasari_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = get_words_from_txt(PATH_VAL)\n",
    "nasari_dict = nasari_to_dict(PATH_NASARI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recupero synset da SemEval17_IT_senses2synsets.txt\n",
    "Da file recupero ogni possibile babelId associato al nostro termine da valutare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_babel_syns(word, path):\n",
    "    babel_list = []\n",
    "    flag = False\n",
    "    with open(path, 'r', encoding=\"utf8\") as file: \n",
    "        for line in file.readlines():\n",
    "            if word in line:\n",
    "                flag = True\n",
    "            elif flag and line[0] != '#':\n",
    "                babel_list.append(line)\n",
    "            else:\n",
    "                flag = False\n",
    "    return babel_list                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcolo similarità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(vec1, vec2):\n",
    "    return 1 - spatial.distance.cosine(vec1, vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcolo il massimo tra i valori di similarità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nasari_valutation(syn1, syn2, nasari_dict):\n",
    "    max = 0.0\n",
    "    max_elem = (None, None)\n",
    "    for s1 in syn1:\n",
    "        for s2 in syn2:\n",
    "            if s1.strip('\\n') in nasari_dict.keys() and s2.strip('\\n') in nasari_dict.keys():\n",
    "                test1 = list(map(float, nasari_dict[s1.strip('\\n')]))\n",
    "                test2 = list(map(float, nasari_dict[s2.strip('\\n')]))\n",
    "                sim = cos_sim(test1, test2)\n",
    "                if sim > max:\n",
    "                    max = sim\n",
    "                    max_elem = (s1.strip('\\n'), s2.strip('\\n'))\n",
    "    return max, max_elem\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valutazione accuratezza del sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sense_valutation(user_syn, system_syn):\n",
    "    i = 0\n",
    "    unit_score = 0\n",
    "    couple_score = 0\n",
    "    for syn in system_syn:\n",
    "        if syn[0] in user_syn:\n",
    "            unit_score += 1\n",
    "        if syn[1] in user_syn:\n",
    "            unit_score += 1\n",
    "            \n",
    "    for syn in system_syn:\n",
    "        if syn[0] == user_syn[i] and syn[1] == user_syn[i+1]:\n",
    "            couple_score += 1 \n",
    "        i += 2\n",
    "    return f\"elementi singoli: {unit_score/100}, coppie: {couple_score/50}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recupero termini affini da BabelNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terms_by_babel_id(babel_id):\n",
    "    res = []\n",
    "    x = requests.get(URL.format(babel_id,KEY))\n",
    "    if x.status_code != 400:\n",
    "        s = x.json()['senses']\n",
    "        for sense in s:\n",
    "            res.append(sense['properties']['fullLemma'])   \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esecuzione\n",
    " - Consegna 1:\n",
    "      \n",
    "        1. salvo i valori di similarità forniti in fase di annotazione, il loro valore medio e i synset scelti per produrre l'annotazione\n",
    "        2. calcolo indici di correlazione tra annotazione dei due annotatori\n",
    "        3. recupero i babelsyns associati ai termini annotati\n",
    "        4. calcolo la massima similarità usando i vettori di NASARI\n",
    "        5. calcolo indici di correlazione tra i valori in output dal sistema e quelli forniti in fase di annotazione\n",
    "       \n",
    "- Consegna 2:\n",
    "\n",
    "        1. calcolo del punteggio Kappa di Cohen tra i valori forniti dai due anotatori\n",
    "        2. stampa degli elementi che massimizzano lo score di similarità            \n",
    "        3. calcolo dell'accuratezza su singoli elementi e su coppie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIZIO CONSEGNA 1\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "Correlazione di Spearman tra annotatori: 0.8969380835014799\n",
      "\n",
      "\n",
      "Correlazione di Pearson tra annotatori: 0.9316329502979277\n",
      "\n",
      "---------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "Correlazione di Spearman tra media annotatori e sistema: 0.6954175730833376\n",
      "\n",
      "\n",
      "Correlazione di Pearson tra media annotatori e sistema: 0.5896111095272338\n",
      "\n",
      "---------------------------------------------------------------------------------------\n",
      "INIZIO CONSEGNA 2\n",
      "\n",
      "Punteggio Kappa di Cohen tra annotatori: 0.7981632859017055\n",
      "\n",
      "('cricket', 'sostenitore'), ('bn:00023796n', 'bn:01317296n'), ['grillo', 'cricket', 'gryllidae'], ['sostegni_(araldica)', 'sostegni', 'Supporti', 'Sostegno_(araldica)']\n",
      "\n",
      "('scultura', 'statua'), ('bn:00069924n', 'bn:00074064n'), ['scultura', 'scultore', 'scultori', 'scultrice'], ['statua', 'statuaria', 'statue', 'gruppo_scultoreo']\n",
      "\n",
      "('browser', 'Mozilla Firefox'), ('bn:00013447n', 'bn:01387235n'), ['browser', 'browser_web', 'navigatore', 'web_browser'], ['Mozilla_Firefox', 'Firefox', 'Electrolysis', 'Minefield']\n",
      "\n",
      "('Fox Terrier', 'Canon'), ('bn:03237376n', 'bn:03476756n'), ['Fox_Terrier', 'Fox_Terrier_a_pelo_liscio', 'fox_terrier_a_pelo_ruvido', 'fox_terrier'], ['Canon_(manga)', 'Canon']\n",
      "\n",
      "('HSBC', 'Gran Bretagna'), ('bn:02580408n', 'bn:00013173n'), ['HSBC', 'HSBC_Holdings', 'Hong_Kong_and_Shanghai_Banking_Corporation', 'Hsbc'], ['GB', 'Gran_Bretagna', 'Inghilterra', 'Regno_Unito']\n",
      "\n",
      "('Bibbia', 'Vangelo'), ('bn:00010217n', 'bn:00031976n'), ['Bibbia', 'bibbia', 'sacra_scrittura', 'Sacra_Bibbia'], ['evangelo', 'vangelo', 'Vangelo', 'Nascita_dei_vangeli']\n",
      "\n",
      "('vestito', 'danza'), ('bn:00028682n', 'bn:00010152n'), ['abito', 'toilette', 'veste', 'vestito'], ['fidanzamento', 'promessa_di_matrimonio', 'fidanzata', 'promessa']\n",
      "\n",
      "('array', 'lista'), ('bn:00005869n', 'bn:00051510n'), ['array', 'vettore'], ['elenco', \"l'elaborazione_della_lista\"]\n",
      "\n",
      "('cella', 'gattabuia'), ('bn:00017031n', 'bn:00064468n'), ['cella_(prigione)', 'cella', 'carcere_cella', 'cella_di_prigione'], ['carcere', 'casa_circondariale', 'casa_di_detenzione', 'casa_di_pena']\n",
      "\n",
      "('saggio', 'compito a casa'), ('bn:00021410n', 'bn:00069626n'), ['componimento', 'elaborato', 'relazione'], ['compiti_a_casa', 'compiti_per_casa', 'compiti_scolastici', 'compito']\n",
      "\n",
      "('computer', 'macchina'), ('bn:00054739n', 'bn:02730666n'), ['PC', 'personal_computer', 'microcomputer', 'Microcomputer'], ['macchina']\n",
      "\n",
      "('panda', 'orso polare'), ('bn:00002177n', 'bn:00045719n'), ['Ailurus_fulgens', 'panda', 'panda_minore', 'Ailurus'], ['orso_bianco', 'orso_polare', 'Ursus_Maritimus', 'Ursus_maritimus']\n",
      "\n",
      "('nevrosi', 'mente'), ('bn:00057430n', 'bn:00012682n'), ['neurosi', 'nevrosi', 'psiconeurosi', 'psiconevrosi'], ['aquila', 'cervello', 'cima', 'genio']\n",
      "\n",
      "('campagna', 'scimmia'), ('bn:03520751n', 'bn:02131227n'), [\"Torre_d'Isola\", 'Torredisolani', \"torre_d'isola\"], ['Scimmia_(zodiaco_cinese)', 'Scimmia']\n",
      "\n",
      "('costante di Faraday', 'zaino'), ('bn:00033657n', 'bn:00007752n'), ['Faraday', 'M.-Faraday', 'Michael_Faraday', 'Micheal_Faraday'], ['bisaccia', 'saccapane', 'tascapane', 'zainetto']\n",
      "\n",
      "('palazzo', 'grattacielo'), ('bn:00013722n', 'bn:00044044n'), ['costruzione', 'edificazione', 'edificio', 'fabbricato'], ['casa_a_torre', 'condominio', 'grattacielo', 'edifici_alti']\n",
      "\n",
      "('elicottero', 'aereo'), ('bn:00018734n', 'bn:00001697n'), ['elicottero', 'elicotteri', 'whirlybird'], ['aereo', 'aeroplano', 'apparecchio', 'areoplano']\n",
      "\n",
      "('UniversitÃ\\xa0 di Cambridge', 'UniversitÃ\\xa0 di Oxford'), (None, None), [], []\n",
      "\n",
      "('bandiera', 'asta'), ('bn:14407671n', 'bn:00063293n'), ['bandiera'], ['asta', 'palo', 'stanga']\n",
      "\n",
      "('finestra', 'tetto'), ('bn:00081285n', 'bn:00068220n'), ['finestra', 'bordo_della_finestra', 'davanzale', 'davanzale_della_finestra'], ['copertura', 'tetto', 'tetti', 'copertura_(architettura)']\n",
      "\n",
      "('gioco di carte', 'frisbee'), ('bn:00015923n', 'bn:00036583n'), ['gioco_di_carte', 'giochi_di_carte', 'Giochi_con_le_carte', 'Gioco_con_le_carte'], ['frisbee', 'Frisbee', 'Freesbee', 'Freesbi']\n",
      "\n",
      "('malware', 'worm'), ('bn:01363738n', 'bn:00081636n'), ['malware', 'software_dannoso', 'software_malintenzionato', 'software_pericoloso'], ['worm', 'verme']\n",
      "\n",
      "('pianeta', 'stella'), ('bn:00052888n', 'bn:00073964n'), ['pianeta', 'Classificazione_planetaria', 'Formazione_dei_pianeti', 'pianeti'], ['astro', 'sole', 'stella', 'stelle']\n",
      "\n",
      "('corridore', 'atleta'), ('bn:00068572n', 'bn:00006747n'), ['corridore'], ['atleta', 'sportivo', 'personalità_legata_allo_sport', 'sportiva']\n",
      "\n",
      "('calibro', 'ombrello'), ('bn:00054021n', 'bn:00078920n'), ['misura'], ['ombrello', 'ombrellone', 'paracqua', 'parapioggia']\n",
      "\n",
      "('WiFi', 'WikiLeaks'), ('bn:00081176n', 'bn:03777357n'), ['Wi-Fi', 'wireless_local_area_network', 'Wireless_Local_Area_Network', 'Connessione_senza_fili'], ['WikiLeaks', 'Cablegate', 'Pubblicazione_dei_documenti_diplomatici_statunitensi', 'Wikileaks']\n",
      "\n",
      "('siccitÃ\\xa0', 'acqua'), (None, None), [], []\n",
      "\n",
      "('aeroporto', 'pezzo'), ('bn:03252503n', 'bn:00060967n'), ['aeroporto'], ['appezzamento', 'lotto', 'orticello', 'terreno']\n",
      "\n",
      "('orchestra', 'banda'), ('bn:00059285n', 'bn:00008280n'), ['orchestra', 'orchestra_filarmonica', 'orchestra_sinfonica', 'orchestre'], ['banda', 'musica', 'complesso', 'gruppo_musicale']\n",
      "\n",
      "('mojito', 'mohito'), ('bn:01361585n', 'bn:01361585n'), ['mojito', 'Mojito', 'Mohito'], ['mojito', 'Mojito', 'Mohito']\n",
      "\n",
      "('programma', 'esame'), ('bn:01245565n', 'bn:00032089n'), ['programma'], ['compito_in_classe', 'esame', 'prova', 'test']\n",
      "\n",
      "('teorema', 'teoria'), ('bn:00076831n', 'bn:02862916n'), ['teorema', 'teorema_matematico', 'teoremi'], ['teoria']\n",
      "\n",
      "('yo-yo', 'giocattolo'), ('bn:00081921n', 'bn:00062965n'), ['yo-yo', 'Yo-yo', 'yo_yo', 'Io-io'], ['balocco', 'gingillo', 'giocattolo', 'gioco']\n",
      "\n",
      "('tormenta', 'pioggia'), ('bn:00074458n', 'bn:00066032n'), ['bufera', 'buriana', 'burrasca', 'fortunale'], ['acqua', 'pioggia', 'acqua_piovana', 'acque_piovane']\n",
      "\n",
      "('storico', 'storiografo'), ('bn:00044258n', 'bn:00044258n'), ['storico', 'storiografo', 'storica', 'storiografa'], ['storico', 'storiografo', 'storica', 'storiografa']\n",
      "\n",
      "('Siemens', 'treno elettrico'), (None, None), [], []\n",
      "\n",
      "('secolo', 'anno'), ('bn:00001939n', 'bn:00004401n'), ['anno', 'eternità', 'molto_tempo', 'secolo'], ['anno', 'anno_gregoriano', 'anomalistico_anno', 'ma']\n",
      "\n",
      "('lega', 'acciaio'), ('bn:00002936n', 'bn:00074123n'), ['lega', 'lega_(metallurgia)', 'lega_metallica', 'leghe_metalliche'], ['acciaio', 'acciaro', \"industria_dell'acciaio\", 'acciai']\n",
      "\n",
      "('magistrato', 'giudice'), ('bn:00048488n', 'bn:00048488n'), ['giudice', 'magistrato', 'pretore', 'giùdice'], ['giudice', 'magistrato', 'pretore', 'giùdice']\n",
      "\n",
      "('caos', 'classe'), ('bn:00003840n', 'bn:00049570n'), ['anarchia', 'caos', 'Anarchica', 'Anarchiche'], ['classe_lavoratrice', 'classe_operaia', 'popolo', 'proletariato']\n",
      "\n",
      "('formazione a distanza', 'internet'), ('bn:00022863n', 'bn:00024712n'), ['corso_per_corrispondenza', 'formazione_a_distanza', 'corrispondenza_corso', 'corsi_per_corrispondenza'], ['cyberspazio', 'internet', 'Internet', 'rete']\n",
      "\n",
      "('sabbia', 'piede'), ('bn:00069126n', 'bn:00008782n'), ['arena', 'rena', 'sabbia', 'sabbie'], ['base', 'piedestallo', 'piedistallo', 'sottofondo']\n",
      "\n",
      "('IMF', 'Deutsche Bank'), (None, None), [], []\n",
      "\n",
      "('Guardian', 'Times'), ('bn:00896958n', 'bn:00056300n'), ['Guardian_(Marvel_Comics)', 'Guardian'], ['moltiplica', 'moltiplicazione', 'moltiplicazioni', 'regola_dei_segni_del_prodotto']\n",
      "\n",
      "('baco da seta', 'Via della Seta'), ('bn:00011961n', 'bn:00071602n'), ['baco_da_seta', 'Bombyx_mori', 'Bachi_da_seta', 'Baco_da_seta'], ['via_della_seta', 'La_via_della_seta', 'Vie_della_Seta', 'Via_della_Seta']\n",
      "\n",
      "('libertÃ\\xa0', 'oasi'), (None, None), [], []\n",
      "\n",
      "('citoplasma', 'dito'), ('bn:00024905n', 'bn:00024979n'), ['citoplasma', 'sarcoplasma', 'citoplasmatica', 'cytol'], ['digito', 'dito', 'dita', 'polpastrello']\n",
      "\n",
      "('protestante', 'cristiano'), ('bn:00064869n', 'bn:00018828n'), ['protestantesimo', 'Protestantesimo', 'Chiesa_Protestante', 'Chiese_protestanti'], ['cristianesimo', 'Cristianesimo', 'cristianità', 'Chiese_cristiane']\n",
      "\n",
      "('Leonardo da Vinci', \"L'Ultima Cena\"), ('bn:00024948n', 'bn:03599114n'), ['Leonardo', 'Leonardo_da_Vinci', 'Leonardo_di_ser_Piero_da_Vinci', 'da_Vinci'], ['Ultima_Cena_(Leonardo)', 'Ultima_Cena', 'Cenacolo_vinciano', 'Il_Cenacolo']\n",
      "\n",
      "('mappa', 'piazza'), ('bn:00036821n', 'bn:00053459n'), ['funzione', 'funzione_matematica', 'funzione_(matematica)', 'mappa_(matematica)'], ['mercato', 'piazza']\n",
      "\n",
      "---------------------------------------------------------------------------------------\n",
      "Accuratezza tra sistema e annotazione di Andrea: elementi singoli: 0.5, coppie: 0.3\n",
      "Accuratezza tra sistema e annotazione di Fabio: elementi singoli: 0.52, coppie: 0.34\n",
      "---------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def mult(res):\n",
    "    return res*4\n",
    "\n",
    "result = []\n",
    "result_elem = []\n",
    "andrea_syn, fabio_syn = get_synsets_from_txt(PATH_SYN)\n",
    "andrea_val, fabio_val, mean_val = get_valutation_from_txt(PATH_VAL)\n",
    "\n",
    "print(\"INIZIO CONSEGNA 1\")\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "print(f\"\\nCorrelazione di Spearman tra annotatori: {stats.spearmanr(andrea_val, fabio_val).correlation}\\n\")\n",
    "print(f\"\\nCorrelazione di Pearson tra annotatori: {stats.pearsonr(andrea_val, fabio_val)[0]}\\n\")\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "for tuple in words:\n",
    "    syn_1 = get_babel_syns(tuple[0], PATH_SEM)\n",
    "    syn_2 = get_babel_syns(tuple[1], PATH_SEM)\n",
    "    \n",
    "    sim_max, elements = get_nasari_valutation(syn_1, syn_2, nasari_dict)\n",
    "    \n",
    "    result.append(sim_max)\n",
    "    result_elem.append(elements)\n",
    "\n",
    "\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "print(f\"\\nCorrelazione di Spearman tra media annotatori e sistema: {stats.spearmanr(result, mean_val).correlation}\\n\")\n",
    "print(f\"\\nCorrelazione di Pearson tra media annotatori e sistema: {stats.pearsonr(result, mean_val)[0]}\\n\")\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "print(\"INIZIO CONSEGNA 2\")\n",
    "\n",
    "print(f\"\\nPunteggio Kappa di Cohen tra annotatori: {cohen_kappa_score(andrea_syn, fabio_syn)}\\n\")\n",
    "\n",
    "i = 0\n",
    "while i < len(result_elem) and i < len(words):\n",
    "    terms_1 = []  \n",
    "    terms_2 = [] \n",
    "\n",
    "    # visualizzo solo i primi 4 termini\n",
    "    for term in list(dict.fromkeys(get_terms_by_babel_id(result_elem[i][0]))):\n",
    "        terms_1.append(term)\n",
    "        if len(terms_1) == 4:\n",
    "            break\n",
    "        \n",
    "    for term in list(dict.fromkeys(get_terms_by_babel_id(result_elem[i][1]))):\n",
    "        terms_2.append(term)\n",
    "        if len(terms_2) == 4:\n",
    "            break\n",
    "\n",
    "    print(f\"{words[i]}, {result_elem[i]}, {terms_1}, {terms_2}\\n\")\n",
    "    i += 1\n",
    "\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "print(f\"Accuratezza tra sistema e annotazione di Andrea: {get_sense_valutation(andrea_syn, result_elem)}\")\n",
    "print(f\"Accuratezza tra sistema e annotazione di Fabio: {get_sense_valutation(fabio_syn, result_elem)}\")\n",
    "print(\"---------------------------------------------------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6847c98a8f86b01c6a19c518cd2f366693b80566b266804d5ca763cbb223f52b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
