{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'C:\\Users\\andre\\Desktop\\Università\\Magistrale\\TLN\\PART 2\\TLN-LAB-PART-2\\resources\\annotations_fabio_andrea.txt'\n",
    "PATH_NASARI = r'C:\\Users\\andre\\Desktop\\Università\\Magistrale\\TLN\\PART 2\\TLN-LAB-PART-2\\resources\\mini_NASARI.tsv'\n",
    "PATH_SEM = r'/home/fazza/Documents/TLN-LAB-PART-2/resources/SemEval17_IT_senses2synsets.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valutation_from_txt(path):\n",
    "    andrea_list = []\n",
    "    fabio_list = []\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            andrea_list.append(float(line.split('    ')[2]))\n",
    "            fabio_list.append(float(line.split('    ')[3]))\n",
    "\n",
    "    return andrea_list, fabio_list\n",
    "\n",
    "def get_words_from_txt(path):\n",
    "    list_of_words = []\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            list_of_words.append((line.split('    ')[0],line.split('    ')[1]))\n",
    "    return list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cricket', 'sostenitore'), ('scultura', 'statua'), ('browser', 'Mozilla Firefox'), ('Fox Terrier', 'Canon'), ('HSBC', 'Gran Bretagna'), ('Bibbia', 'Vangelo'), ('vestito', 'danza'), ('array', 'lista'), ('cella', 'gattabuia'), ('saggio', 'compito a casa'), ('computer', 'macchina'), ('panda', 'orso polare'), ('nevrosi', 'mente'), ('campagna', 'scimmia'), ('costante di Faraday', 'zaino'), ('palazzo', 'grattacielo'), ('elicottero', 'aereo'), ('UniversitÃ\\xa0 di Cambridge', 'UniversitÃ\\xa0 di Oxford'), ('bandiera', 'asta'), ('finestra', 'tetto'), ('gioco di carte', 'frisbee'), ('malware', 'worm'), ('pianeta', 'stella'), ('corridore', 'atleta'), ('calibro', 'ombrello'), ('WiFi', 'WikiLeaks'), ('siccitÃ\\xa0', 'acqua'), ('aeroporto', 'pezzo'), ('orchestra', 'banda'), ('mojito', 'mohito'), ('programma', 'esame'), ('teorema', 'teoria'), ('yo-yo', 'giocattolo'), ('tormenta', 'pioggia'), ('storico', 'storiografo'), ('Siemens', 'treno elettrico'), ('secolo', 'anno'), ('lega', 'acciaio'), ('magistrato', 'giudice'), ('caos', 'classe'), ('formazione a distanza', 'internet'), ('sabbia', 'piede'), ('IMF', 'Deutsche Bank'), ('Guardian', 'Times'), ('baco da seta', 'Via della Seta'), ('libertÃ\\xa0', 'oasi'), ('citoplasma', 'dito'), ('protestante', 'cristiano'), ('Leonardo da Vinci', \"L'Ultima Cena\"), ('mappa', 'piazza')]\n",
      "\n",
      "SPEARMAN'S CORRELATION COEFFICIENT\n",
      "\n",
      "0.8969380835014799\n",
      "\n",
      "PEARSON'S CORRELATION COEFFICIENT\n",
      "\n",
      "(0.9316329502979277, 9.705442539988503e-23)\n"
     ]
    }
   ],
   "source": [
    "a,f = get_valutation_from_txt(PATH)\n",
    "words = get_words_from_txt(PATH)\n",
    "print(words)\n",
    "#print(f\"Lista di Andrea: {a}\")\n",
    "#print(f\"Lista di Fabio: {f}\")\n",
    "\n",
    "print(\"\\nSPEARMAN'S CORRELATION COEFFICIENT\\n\")\n",
    "print(f\"{stats.spearmanr(a, f).correlation}\")\n",
    "\n",
    "print(\"\\nPEARSON'S CORRELATION COEFFICIENT\\n\")\n",
    "print(f\"{stats.pearsonr(a, f)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recupero vettori di NASARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nasari_to_dict(path):\n",
    "    nasari_dict = {}\n",
    "    with open(path, 'r', encoding=\"utf8\") as file:\n",
    "        for line in file.readlines():\n",
    "            splitted_line = line.split('\\t')\n",
    "            nasari_dict[splitted_line[0].split('__')[0]] = splitted_line[1:]\n",
    "    return nasari_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recupero synset da SemEval17_IT_senses2synsets.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_babel_syns(word, path):\n",
    "    babel_list = []\n",
    "    flag = False\n",
    "    with open(path, 'r', encoding=\"utf8\") as file: \n",
    "        for line in file.readlines():\n",
    "            if word in line:\n",
    "                flag = True\n",
    "            elif flag and line[0] != '#':\n",
    "                babel_list.append(line)\n",
    "            else:\n",
    "                flag = False\n",
    "    return babel_list                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasari_dict = nasari_to_dict(PATH_NASARI)\n",
    "#print(nasari_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bn:13846629n\\n', 'bn:03445588n\\n', 'bn:00002177n\\n', 'bn:17685929n\\n', 'bn:00002174n\\n', 'bn:08919261n\\n', 'bn:08842687n\\n', 'bn:08979574n\\n', 'bn:02414200n\\n', 'bn:01794969n\\n']\n"
     ]
    }
   ],
   "source": [
    "babel_list = get_babel_syns('panda', PATH_SEM)\n",
    "print(babel_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6847c98a8f86b01c6a19c518cd2f366693b80566b266804d5ca763cbb223f52b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
