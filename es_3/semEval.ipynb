{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_VAL = r'/home/fazza/Documents/TLN-LAB-PART-2/resources/annotations_fabio_andrea.txt'\n",
    "PATH_SYN = r'/home/fazza/Documents/TLN-LAB-PART-2/resources/babel_synset.txt'\n",
    "PATH_NASARI = r'/home/fazza/Documents/TLN-LAB-PART-2/resources/mini_NASARI.tsv'\n",
    "PATH_SEM = r'/home/fazza/Documents/TLN-LAB-PART-2/resources/SemEval17_IT_senses2synsets.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synsets_from_txt(path):\n",
    "    andrea_list = []\n",
    "    fabio_list = []\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            andrea_list.append(line.split('    ')[2])\n",
    "            andrea_list.append(line.split('    ')[3])\n",
    "            fabio_list.append(line.split('    ')[4])\n",
    "            fabio_list.append(line.split('    ')[5])\n",
    "    \n",
    "    return andrea_list, fabio_list\n",
    "\n",
    "def get_valutation_from_txt(path):\n",
    "    andrea_list = []\n",
    "    fabio_list = []\n",
    "    mean_list = []\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            andrea_list.append(float(line.split('    ')[2]))\n",
    "            fabio_list.append(float(line.split('    ')[3]))\n",
    "            mean_list.append(float(line.split('    ')[4]))\n",
    "\n",
    "    return andrea_list, fabio_list, mean_list\n",
    "\n",
    "def get_words_from_txt(path):\n",
    "    list_of_words = []\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            list_of_words.append((line.split('    ')[0],line.split('    ')[1]))\n",
    "    return list_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recupero vettori di NASARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nasari_to_dict(path):\n",
    "    nasari_dict = {}\n",
    "    with open(path, 'r', encoding=\"utf8\") as file:\n",
    "        for line in file.readlines():\n",
    "            splitted_line = line.split('\\t')\n",
    "            nasari_dict[splitted_line[0].split('__')[0]] = splitted_line[1:]\n",
    "            \n",
    "    return nasari_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words = get_words_from_txt(PATH_VAL)\n",
    "nasari_dict = nasari_to_dict(PATH_NASARI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recupero synset da SemEval17_IT_senses2synsets.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_babel_syns(word, path):\n",
    "    babel_list = []\n",
    "    flag = False\n",
    "    with open(path, 'r', encoding=\"utf8\") as file: \n",
    "        for line in file.readlines():\n",
    "            if word in line:\n",
    "                flag = True\n",
    "            elif flag and line[0] != '#':\n",
    "                babel_list.append(line)\n",
    "            else:\n",
    "                flag = False\n",
    "    return babel_list                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo similarità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(vec1, vec2):\n",
    "    return 1 - spatial.distance.cosine(vec1, vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo il massimo tra i valori di similarità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nasari_valutation(syn1, syn2, nasari_dict):\n",
    "    max = 0.0\n",
    "    max_elem = (None, None)\n",
    "    for s1 in syn1:\n",
    "        for s2 in syn2:\n",
    "            if s1.strip('\\n') in nasari_dict.keys() and s2.strip('\\n') in nasari_dict.keys():\n",
    "                test1 = list(map(float, nasari_dict[s1.strip('\\n')]))\n",
    "                test2 = list(map(float, nasari_dict[s2.strip('\\n')]))\n",
    "                sim = cos_sim(test1, test2)\n",
    "                if sim > max:\n",
    "                    max = sim\n",
    "                    max_elem = (s1.strip('\\n'), s2.strip('\\n'))\n",
    "    return max, max_elem\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult(res):\n",
    "    return res*4\n",
    "\n",
    "result = []\n",
    "result_elem = []\n",
    "andrea_syn, fabio_syn = get_synsets_from_txt(PATH_SYN)\n",
    "andrea_val, fabio_val, mean_val = get_valutation_from_txt(PATH_VAL)\n",
    "\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "print(f\"\\nCorrelazione di Spearman tra annotatori: {stats.spearmanr(andrea_val, fabio_val).correlation}\\n\")\n",
    "print(f\"\\nCorrelazione di Pearson tra annotatori: {stats.pearsonr(andrea_val, fabio_val)}\\n\")\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "for tuple in words:\n",
    "    syn_1 = get_babel_syns(tuple[0], PATH_SEM)\n",
    "    syn_2 = get_babel_syns(tuple[1], PATH_SEM)\n",
    "    \n",
    "    sim_max, elements = get_nasari_valutation(syn_1, syn_2, nasari_dict)\n",
    "    #print(tuple, elements, #lista(elements[0]), #lista(elements[1]))\n",
    "    \n",
    "    result.append(sim_max)\n",
    "    result_elem.append(elements)\n",
    "\n",
    "\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "print(f\"\\nCorrelazione di Spearman tra media annotatori e sistema: {stats.spearmanr(result, mean_val).correlation}\\n\")\n",
    "print(f\"\\nCorrelazione di Pearson tra media annotatori e sistema: {stats.pearsonr(result, mean_val)}\\n\")\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(f\"\\nPunteggio Cohen Kappa tra annotatori: {cohen_kappa_score(andrea_syn, fabio_syn)}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('spacy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3525effbb77994477fa12acef781f772c9be5a5a62ddcd46b88c81c6046781ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
