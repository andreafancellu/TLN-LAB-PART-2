{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.nltk.org/howto/wordnet.html WordNet examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funzione per trovare tutti gli iperonimi di un synset e salvarli in una lista di liste\n",
    " [ [iperonimi di livello1, ...], [iperonimi di livello 2, ...], ... , [...] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Synset('canine.n.02'), Synset('domestic_animal.n.01')], [Synset('carnivore.n.01')], [Synset('placental.n.01')], [Synset('mammal.n.01')], [Synset('vertebrate.n.01')], [Synset('chordate.n.01')], [Synset('animal.n.01')], [Synset('organism.n.01')], [Synset('living_thing.n.01')], [Synset('whole.n.02')], [Synset('object.n.01')], [Synset('physical_entity.n.01')], [Synset('entity.n.01')]]\n"
     ]
    }
   ],
   "source": [
    "def get_all_hypernyms(synset):\n",
    "    ret_list = []\n",
    "    temp_list = []\n",
    "    hypernyms = synset.hypernyms()\n",
    "    while hypernyms:\n",
    "        for hyper in hypernyms:\n",
    "            temp_list.append(hyper)\n",
    "        ret_list.append(temp_list)\n",
    "        temp_list = []\n",
    "        hypernyms = hypernyms[0].hypernyms()\n",
    "    return ret_list\n",
    "\n",
    "\n",
    "print(get_all_hypernyms(wn.synsets('dog')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funzione che calcola LCS\n",
    "Risalendo la gerarchia degli iperonimi dei due sensi, trovo il primo antenato comune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_lowest_common_subsumer(syn1, syn2):\n",
    "    syn1_hypernyms = sum(get_all_hypernyms(syn1), [])\n",
    "    syn2_hypernyms = sum(get_all_hypernyms(syn2), [])\n",
    "\n",
    "    for h1 in syn1_hypernyms:\n",
    "        if h1 in syn2_hypernyms:\n",
    "            return h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('entity.n.01')]\n",
      "Synset('entity.n.01')\n"
     ]
    }
   ],
   "source": [
    "print(wn.synsets('dog')[1].lowest_common_hypernyms(wn.synsets('happiness')[1]))\n",
    "print(my_lowest_common_subsumer(wn.synsets('dog')[1], wn.synsets('happiness')[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metodo che restituisce la profondità del synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_synset(syn):\n",
    "    if syn is not None:\n",
    "        return 1 if syn.hypernyms() == [] else 1 + depth_synset(syn.hypernyms()[0])\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metodo per calcolare la profondità massima\n",
    "Restituisce sempre 19, per velocizzare le esecuzioni salviamo il valore in una costante (DEPTH_MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_path(): \n",
    "    max_path = 0\n",
    "    for synset in wn.all_synsets():\n",
    "        if synset.max_depth() > max_path:\n",
    "            max_path = synset.max_depth()\n",
    "    return max_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPTH_MAX = 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzione che calcola la distanza tra due synset\n",
    "1. Salviamo gli iperonimi di entrambi i sensi, sia a livelli che come lista\n",
    "2. Per entrambe le liste di iperonimi (s1_hyper, s2_hyper):\n",
    "    \n",
    "    a. scorro tutti i livelli della lista [ [iperonimi di livello1, ...], [iperonimi di livello 2, ...], ... ]\n",
    "    \n",
    "    b. scorro tutti gli iperonimi per ogni livello\n",
    "    \n",
    "    c. per ogni iperonimo, se è presente nella lista di iperonimi del **secondo synset in input**, allora quello è l'antenato comune.\n",
    "        Più nel dettaglio, se il contatore vale 0, cioè non abbiamo ancora incontrato nessun'altro antenato comune, lo incremento con il valore di nodi di distanza dal **primo synset in input**. Ciò significa che il synset in questione è un antenato comune\n",
    "3. Restituisco la somma dei contatori\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "def my_distance_between_syn(syn_1, syn_2):\n",
    "    if syn_1 == syn_2:\n",
    "        return 0\n",
    "    \n",
    "    s1_hyper = get_all_hypernyms(syn_1)\n",
    "    s2_hyper = get_all_hypernyms(syn_2)\n",
    "\n",
    "    s1_temp = sum(s1_hyper, []) \n",
    "    s2_temp = sum(s2_hyper, []) \n",
    "    \n",
    "\n",
    "    c_1 = 0\n",
    "    for i in range(0, len(s1_hyper)):\n",
    "        for j in range(0, len(s1_hyper[i])):\n",
    "            if s1_hyper[i][j] in s2_temp and c_1 == 0:\n",
    "                c_1 += i+1\n",
    "\n",
    "    c_2 = 0\n",
    "    for i in range(0, len(s2_hyper)):\n",
    "        for j in range(0, len(s2_hyper[i])):\n",
    "            if s2_hyper[i][j] in s1_temp and c_2 == 0:\n",
    "                c_2 += i+1\n",
    "    \n",
    "    if c_1 > 0 and c_2 > 0:\n",
    "        return (c_1+c_2)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "print(wn.synsets('car')[0].shortest_path_distance(wn.synsets('dog')[0]))\n",
    "print(my_distance_between_syn(wn.synsets('car')[0], wn.synsets('dog')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wu & Palmer\n",
    "Resituisce valori tra 0 e 1, dove più ci si avvicina a 1 più i sensi sono simili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wu_palmer(syn1, syn2):\n",
    "    dep = 0\n",
    "\n",
    "    lcs = my_lowest_common_subsumer(syn1, syn2)\n",
    "    dep = (depth_synset(syn1) + depth_synset(syn2))\n",
    "    \n",
    "    if dep == 0:\n",
    "        dep = 0.001\n",
    "        \n",
    "    return 2 * depth_synset(lcs) / dep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortest Path\n",
    "Valore che può oscillare tra 0 e 2 * depthMax.\n",
    "Più il valore si avvicina a 2 * depthMax più i sensi sono simili, questo vuol dire che la distanza tra i due sensi (len(s1,s2)) è minima o uguale a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path(syn1, syn2):\n",
    "    return 2 * DEPTH_MAX - my_distance_between_syn(syn1, syn2) if my_distance_between_syn(syn1, syn2) is not None else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leakcock & Chodorow\n",
    "I valori sono compresi tra 0 e log(2depthMax + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leakcock_chodorow(syn1, syn2):\n",
    "    distance = my_distance_between_syn(syn1, syn2) \n",
    "    if distance is not None:\n",
    "        if distance != 0:\n",
    "            return -np.log(distance / 2 * DEPTH_MAX)\n",
    "        else:\n",
    "             return -np.log(distance+1 / (2 * DEPTH_MAX)+1)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esecuzione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lettura delle coppie di termini dal file WordSim353.csv e recupero dei relativi synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "with open(r'../resources/WordSim353.csv', 'r') as f:\n",
    "    word_sim = f.readlines()[1:]\n",
    "    for tuple in word_sim:\n",
    "        dataset.append(tuple.split(','))\n",
    "\n",
    "syns_1 = []\n",
    "syns_2 = []\n",
    "\n",
    "for tuple in dataset:\n",
    "    syns_1.append(wn.synsets(tuple[0]))\n",
    "    syns_2.append(wn.synsets(tuple[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo della similarità, utilizzando le tre metriche implementate. Faccio il prodotto cartesiano dei synset delle due parole in input e calcolo la similarità per ogni coppia di synset. Per ogni coppia di termini, prendo il valore massimo di similarità per ogni metrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp = []\n",
    "sp = []\n",
    "lc = []\n",
    "\n",
    "max_wu = 0\n",
    "max_sp = 0\n",
    "max_lc = 0\n",
    "\n",
    "for i in range(len(syns_1)):\n",
    "    for j in range(len(syns_1[i])):\n",
    "        for k in range(len(syns_2[i])):\n",
    "            \n",
    "            \n",
    "            wu_temp = wu_palmer(syns_1[i][j], syns_2[i][k])\n",
    "            sp_temp = shortest_path(syns_1[i][j], syns_2[i][k])\n",
    "            lc_temp = leakcock_chodorow(syns_1[i][j], syns_2[i][k])\n",
    "\n",
    "            if wu_temp > float(max_wu):\n",
    "                max_wu = wu_temp\n",
    "            if sp_temp > float(max_sp):\n",
    "                max_sp = sp_temp\n",
    "            if lc_temp < float(max_lc):\n",
    "                max_lc = lc_temp\n",
    "\n",
    "    wp.append(max_wu) \n",
    "    max_wu = 0\n",
    "    sp.append(max_sp)\n",
    "    max_sp = 0\n",
    "    lc.append(max_lc)\n",
    "    max_lc = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodi di valutazione\n",
    "Lettura dei valori di similarità nel file WordSim353.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sim_353 = [float(data[2].strip('\\n')) for data in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcolo dei valori di correlazione di Spearman e Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SPEARMAN'S CORRELATION COEFFICIENT\n",
      "\n",
      "WU & PALMER             0.31085037768164225\n",
      "SHORTEST PATH           0.27075321829782795\n",
      "LEAKCOCK & CHODOROW     0.14485364030465941\n",
      "\n",
      "\n",
      "\n",
      "PEARSON'S CORRELATION COEFFICIENT\n",
      "\n",
      "WU & PALMER             (0.25357690588394033, 1.389583643256362e-06)\n",
      "SHORTEST PATH           (0.08555125323071107, 0.10858096975665119)\n",
      "LEAKCOCK & CHODOROW     (0.13391553537314543, 0.011786460824796455)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSPEARMAN'S CORRELATION COEFFICIENT\\n\")\n",
    "print(f\"WU & PALMER             {stats.spearmanr(wp, word_sim_353).correlation}\")\n",
    "print(f\"SHORTEST PATH           {stats.spearmanr(sp, word_sim_353).correlation}\")\n",
    "print(f\"LEAKCOCK & CHODOROW     {stats.spearmanr(lc, word_sim_353).correlation}\\n\\n\")\n",
    "\n",
    "print(\"\\nPEARSON'S CORRELATION COEFFICIENT\\n\")\n",
    "print(f\"WU & PALMER             {stats.pearsonr(wp, word_sim_353)}\")\n",
    "print(f\"SHORTEST PATH           {stats.pearsonr(sp, word_sim_353)}\")\n",
    "print(f\"LEAKCOCK & CHODOROW     {stats.pearsonr(lc, word_sim_353)}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6847c98a8f86b01c6a19c518cd2f366693b80566b266804d5ca763cbb223f52b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
